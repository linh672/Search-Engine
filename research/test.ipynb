{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1499952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    }
   ],
   "source": [
    "print(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9e2f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\PC\\\\OneDrive - KU Leuven\\\\Project\\\\Search-Engine\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d501952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61cd342a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\PC\\\\OneDrive - KU Leuven\\\\Project\\\\Search-Engine'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a17ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0259cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Data \n",
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyPDFLoader \n",
    "    )\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29ecca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_file(data=\"Data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4733547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c171c747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 411\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5a94019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08f077b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Embedding Model from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "337353f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1187546d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ") model_name='sentence-transformers/all-MiniLM-L6-v2' cache_folder=None model_kwargs={} encode_kwargs={} query_instruction='Represent this question for searching relevant passages: ' embed_instruction='' show_progress=False\n"
     ]
    }
   ],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "075bdfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "querry_result = embeddings.embed_query(\"Hello World\")\n",
    "print(\"Length\", len(querry_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed431662",
   "metadata": {},
   "source": [
    "Query Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d1e32aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e71286a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7383d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"chatbot\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"chatbot-i3qy2zb.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 384,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"chatbot\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1aa23473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab691321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embed each chunk and upsert the embeddings into Pineconde index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b4f019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x25fbcfffa50>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a3aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ad031c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_docs = retriever.invoke(\"What is the role of the human resource function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9dc89eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='ce45d552-ee1c-4733-981a-ec9890f91959', metadata={'author': 'Jerome Morrissey', 'creationdate': '2018-06-21T11:54:40+03:00', 'creator': 'Microsoft® Word 2016', 'moddate': '2018-06-21T12:00:45+03:00', 'page': 4.0, 'page_label': '5', 'producer': 'Microsoft® Word 2016', 'source': 'Data\\\\HUMAN_RESOURCE_POLICIES_-_GESCI__June_2018.pdf', 'total_pages': 77.0}, page_content='4. The Human Resource Function \\nThe human resource functions shall be managed, on a day-to-day basis by the manager: \\nFinance and Operations or another person so designated by the CEO. Such a person will \\nalso be known as the Human Resource (HR) Manager. Some human resource functions are \\nalso carried out by Managers as, from time to time, delegated to them by the CEO. The CEO \\nretains overall responsibility over the human resource functions. \\n \\n5. The role of the human resource function'),\n",
       " Document(id='ce269d3a-b3ff-4bae-ad71-46735597fa37', metadata={'author': 'Jerome Morrissey', 'creationdate': '2018-06-21T11:54:40+03:00', 'creator': 'Microsoft® Word 2016', 'moddate': '2018-06-21T12:00:45+03:00', 'page': 4.0, 'page_label': '5', 'producer': 'Microsoft® Word 2016', 'source': 'Data\\\\HUMAN_RESOURCE_POLICIES_-_GESCI__June_2018.pdf', 'total_pages': 77.0}, page_content='The roles of the human resource function are to: \\n \\n\\uf0b7 initiate and develop appropriate human resource policies, procedures and practices for the \\nefficient and effective management of GESCI; \\n\\uf0b7 implement and monitor  human resource policies and p rocedures as contained in the \\nManual; \\n\\uf0b7 facilitate the recruitment and hiring of staff; \\n\\uf0b7 assist in the establishment of an organization structure with clearly defined and documented'),\n",
       " Document(id='05d98740-e4e6-4e30-8e05-54003229be1a', metadata={'author': 'Jerome Morrissey', 'creationdate': '2018-06-21T11:54:40+03:00', 'creator': 'Microsoft® Word 2016', 'moddate': '2018-06-21T12:00:45+03:00', 'page': 0.0, 'page_label': '1', 'producer': 'Microsoft® Word 2016', 'source': 'Data\\\\HUMAN_RESOURCE_POLICIES_-_GESCI__June_2018.pdf', 'total_pages': 77.0}, page_content='HUMAN RESOURCE POLICIES \\nAND PROCEDURE MANUAL \\n(HRPPM) \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nREVISED 2018')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "345450f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"gemma3:4b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85abfa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks.\"\n",
    "    \"Use the following pieces of retrieved context to answer the question.\"\n",
    "    \"Use three sentences maximum and keep the answer concise.\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24ee05f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a061877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human resource function is responsible for initiating and developing HR policies and procedures for GESCI. It also facilitates recruitment, hiring, and establishing the organization’s structure, all while monitored by the CEO. The HR Manager, designated by the CEO, oversees these activities.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is the role of the human resource function\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20fde7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m sorry, but the provided context does not contain any information about a “car.” It discusses inventions, travel proposals, and data protection measures within GESCI.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is the car\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search_engine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
